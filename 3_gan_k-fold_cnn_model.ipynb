{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4422851184106451769\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22655533056\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4572494463556360476\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:03:13.178359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 16:03:13.216532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 16:03:13.216644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 16:03:13.268584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 16:03:13.268620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 16:03:13.268745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 16:03:13.269612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 21606 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are manually dividing as we do not want generated GAN MRI in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "image_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pituitary', 'glioma', 'meningioma']\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/Training_GAN'\n",
    "labels = os.listdir(train_path)\n",
    "\n",
    "test_path = 'data/Test_GAN'\n",
    "labels = os.listdir(test_path)\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all of the training and testing data and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training data and their labels.\n",
    "for i in labels:\n",
    "    folder_path = os.path.join(train_path, i)\n",
    "    for j in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, j))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        \n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "\n",
    "# Get the testing data and their labels.\n",
    "for i in labels:\n",
    "    folder_path = os.path.join(test_path, i)\n",
    "    for j in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, j))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        \n",
    "        X_test.append(img)\n",
    "        y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4292, 128, 128, 3), (4292,), (1844, 128, 128, 3), (1844,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn labels into number format for both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "y_test_new = []\n",
    "\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_new = np.array(y_train_new)\n",
    "\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test_new = np.array(y_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold needs 1-dimensional Y array.\n",
    "# Do not convert to_categorical when using StratifiedKFold\n",
    "#y_new = tf.keras.utils.to_categorical(y_new)\n",
    "#y_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get F1Score while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN Model with K-Fold\n",
    "> We have X and y_new. We'll perform K-Fold cross validation<br>\n",
    "**iterative-stratification** is a project that provides scikit-learn compatible cross validators with stratification for multilabel data.<br>\n",
    "`!pip install iterative-stratification`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, StratifiedKFold \n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = tf.keras.utils.to_categorical(y_train_new)\n",
    "y_test_new = tf.keras.utils.to_categorical(y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 15ms/step - loss: 0.1243 - accuracy: 0.9721 - precision: 0.9744 - recall: 0.9721 - get_f1: 0.9714\n",
      "accuracy: 97.21%\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 0.1594 - accuracy: 0.9697 - precision_1: 0.9740 - recall_1: 0.9604 - get_f1: 0.9684\n",
      "accuracy: 96.97%\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9860 - precision_2: 0.9860 - recall_2: 0.9860 - get_f1: 0.9801\n",
      "accuracy: 98.60%\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1051 - accuracy: 0.9814 - precision_3: 0.9837 - recall_3: 0.9814 - get_f1: 0.9832\n",
      "accuracy: 98.14%\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9860 - precision_4: 0.9883 - recall_4: 0.9837 - get_f1: 0.9833\n",
      "accuracy: 98.60%\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 0.9907 - precision_5: 0.9906 - recall_5: 0.9860 - get_f1: 0.9855\n",
      "accuracy: 99.07%\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9814 - precision_6: 0.9836 - recall_6: 0.9814 - get_f1: 0.9832\n",
      "accuracy: 98.14%\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1663 - accuracy: 0.9441 - precision_7: 0.9570 - recall_7: 0.9347 - get_f1: 0.9383\n",
      "accuracy: 94.41%\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1831 - accuracy: 0.9604 - precision_8: 0.9712 - recall_8: 0.9417 - get_f1: 0.9574\n",
      "accuracy: 96.04%\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9837 - precision_9: 0.9882 - recall_9: 0.9790 - get_f1: 0.9842\n",
      "accuracy: 98.37%\n",
      "Accuracy (mean): 97.55% (+/- 1.36%)\n",
      "Precision (mean): 97.97% (+/- 0.99%)\n",
      "Recall (mean): 97.06% (+/- 1.78%)\n",
      "F1 (mean): 97.35% (+/- 1.45%)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "precisionscores = []\n",
    "recallscores = []\n",
    "f1scores = []\n",
    "histories = []\n",
    "\n",
    "fold_no = 1\n",
    "best_fold = 1.5\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train_new):\n",
    "\n",
    "    ## StratifiedKFold needs 1-dimensional Y array.\n",
    "    # Do not convert to_categorical when using StratifiedKFold\n",
    "    # instead, use to_categorical after splitting with k-fold...\n",
    "    #y_new = tf.keras.utils.to_categorical(y_new)\n",
    "    #y_new = tf.keras.utils.to_categorical(y_new)\n",
    "    #test\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(Conv2D(256, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), get_f1])\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(X_train[train], y_train_new[train], epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Save the fold model\n",
    "    model_save_path = f'./fold_models/{fold_no}.h5'\n",
    "    save_model(model, model_save_path, save_format='h5')\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_train[test], y_train_new[test], verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    precisionscores.append(scores[2] * 100)\n",
    "    recallscores.append(scores[3] * 100)\n",
    "    f1scores.append(scores[4] * 100)\n",
    "    histories.append(history)\n",
    "\n",
    "    # take the fold history that has the best loss for our model \n",
    "    if (scores[0] < best_fold):\n",
    "        best_fold_history = history\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "print(\"Accuracy (mean): %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"Precision (mean): %.2f%% (+/- %.2f%%)\" % (np.mean(precisionscores), np.std(precisionscores)))\n",
    "print(\"Recall (mean): %.2f%% (+/- %.2f%%)\" % (np.mean(recallscores), np.std(recallscores)))\n",
    "print(\"F1 (mean): %.2f%% (+/- %.2f%%)\" % (np.mean(f1scores), np.std(f1scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97.20930457115173, 96.96969985961914, 98.60140085220337, 98.13953638076782, 98.60140085220337, 99.06759858131409, 98.13519716262817, 94.40559148788452, 96.03729844093323, 98.36829900741577]\n"
     ]
    }
   ],
   "source": [
    "print(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best performing model and train it\n",
    "> We'll train this model to be our final model to make predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected model\n",
    "# FOLD 9\n",
    "loaded_model = load_model('./fold_models/9.h5', custom_objects={\"get_f1\": get_f1})\n",
    "#loaded_model.summary()\n",
    "\n",
    "X_train.shape, y_train_new.shape, y_test.shape, y_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9813 - precision_8: 0.9822 - recall_8: 0.9797 - get_f1: 0.9809\n",
      "Epoch 1: val_loss improved from inf to 2.25185, saving model to ./final_model.h5\n",
      "135/135 [==============================] - 5s 34ms/step - loss: 0.0601 - accuracy: 0.9814 - precision_8: 0.9822 - recall_8: 0.9797 - get_f1: 0.9811 - val_loss: 2.2519 - val_accuracy: 0.5423 - val_precision_8: 0.5441 - val_recall_8: 0.5418 - val_get_f1: 0.5390\n",
      "Epoch 2/15\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9844 - precision_8: 0.9855 - recall_8: 0.9837 - get_f1: 0.9846\n",
      "Epoch 2: val_loss improved from 2.25185 to 1.29750, saving model to ./final_model.h5\n",
      "135/135 [==============================] - 4s 32ms/step - loss: 0.0510 - accuracy: 0.9844 - precision_8: 0.9855 - recall_8: 0.9837 - get_f1: 0.9847 - val_loss: 1.2975 - val_accuracy: 0.5841 - val_precision_8: 0.5882 - val_recall_8: 0.5803 - val_get_f1: 0.5790\n",
      "Epoch 3/15\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9797 - precision_8: 0.9808 - recall_8: 0.9790 - get_f1: 0.9799\n",
      "Epoch 3: val_loss did not improve from 1.29750\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0590 - accuracy: 0.9797 - precision_8: 0.9809 - recall_8: 0.9790 - get_f1: 0.9801 - val_loss: 1.9104 - val_accuracy: 0.5564 - val_precision_8: 0.5573 - val_recall_8: 0.5564 - val_get_f1: 0.5530\n",
      "Epoch 4/15\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9797 - precision_8: 0.9804 - recall_8: 0.9792 - get_f1: 0.9798\n",
      "Epoch 4: val_loss did not improve from 1.29750\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 0.0536 - accuracy: 0.9797 - precision_8: 0.9804 - recall_8: 0.9793 - get_f1: 0.9800 - val_loss: 2.0298 - val_accuracy: 0.5239 - val_precision_8: 0.5236 - val_recall_8: 0.5168 - val_get_f1: 0.5167\n",
      "Epoch 5/15\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9831 - precision_8: 0.9833 - recall_8: 0.9819 - get_f1: 0.9826\n",
      "Epoch 5: val_loss did not improve from 1.29750\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 0.0518 - accuracy: 0.9832 - precision_8: 0.9834 - recall_8: 0.9821 - get_f1: 0.9829 - val_loss: 1.6525 - val_accuracy: 0.5683 - val_precision_8: 0.5710 - val_recall_8: 0.5667 - val_get_f1: 0.5641\n",
      "Epoch 6/15\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9824 - precision_8: 0.9824 - recall_8: 0.9819 - get_f1: 0.9821\n",
      "Epoch 6: val_loss did not improve from 1.29750\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 0.0565 - accuracy: 0.9825 - precision_8: 0.9825 - recall_8: 0.9821 - get_f1: 0.9824 - val_loss: 1.4325 - val_accuracy: 0.5233 - val_precision_8: 0.5248 - val_recall_8: 0.5211 - val_get_f1: 0.5196\n",
      "Epoch 7/15\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9857 - precision_8: 0.9864 - recall_8: 0.9857 - get_f1: 0.9860\n",
      "Epoch 7: val_loss did not improve from 1.29750\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 0.0420 - accuracy: 0.9853 - precision_8: 0.9860 - recall_8: 0.9853 - get_f1: 0.9858 - val_loss: 1.4336 - val_accuracy: 0.5667 - val_precision_8: 0.5687 - val_recall_8: 0.5656 - val_get_f1: 0.5623\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "checkpoint_path = './final_model'\n",
    "os.mkdir(checkpoint_path)\n",
    "\n",
    "keras_callbacks = [\n",
    "ModelCheckpoint(checkpoint_path + '.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
    "EarlyStopping(monitor='val_loss', mode='min', verbose= 1, patience= 5)\n",
    "]\n",
    "\n",
    "# fit final model.\n",
    "history = loaded_model.fit(X_train, y_train_new, validation_data=(X_test, y_test_new), epochs= 15, batch_size= 32, callbacks= keras_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1844, 128, 128, 3), (1844, 3))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test, verbose=0)\n",
    "yhat_classes = np.argmax(yhat_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1844,), (1844, 3))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_classes.shape, y_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revert from label_encoder to 1-d pred. array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new_2 = np.argmax(y_test_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1844,), (1844,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_classes.shape, y_test_new_2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got predicitons. Now evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test_new_2, yhat_classes)\n",
    "precision = precision_score(y_test_new_2, yhat_classes, average='weighted')\n",
    "recall = recall_score(y_test_new_2, yhat_classes, average='weighted')\n",
    "f1 = f1_score(y_test_new_2, yhat_classes, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5954446854663774 | Precision: 0.7271697835352666 | Recall: 0.5954446854663774 | F1: 0.505723197761198\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {0} | Precision: {1} | Recall: {2} | F1: {3}'.format(acc, precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
